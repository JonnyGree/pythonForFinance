{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "# Get the current working directory\n",
    "current_folder = os.getcwd()\n",
    "modules_path = os.path.join(current_folder, 'modules')\n",
    "sys.path.append(current_folder)\n",
    "sys.path.append(modules_path)\n",
    "\n",
    "restart_command = [sys.executable] + sys.argv\n",
    "\n",
    "# Call subprocess to restart the Python interpreter\n",
    "subprocess.call(restart_command)\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from modules.api_yf import api_yf\n",
    "from modules.db_postgres_utils import db_utils\n",
    "from modules.plotter import pl\n",
    "from modules.processdata import processdata\n",
    "\n",
    "# Define the ETF ticker symbol\n",
    "ticker = 'META'\n",
    "db_utils.connect()\n",
    "\n",
    "# # Get a list of loaded modules\n",
    "# loaded_modules = sys.modules.keys()\n",
    "# # Print the list of loaded modules\n",
    "# print(loaded_modules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db_utils.get_data_from_db(ticker)\n",
    "\n",
    "data2 = processdata.add_daily_return_to_df(data)\n",
    "\n",
    "start_date = processdata.formatDateDt(2021, 1, 1)\n",
    "end_date = processdata.formatDateDt(2023, 1, 1)\n",
    "\n",
    "# Calculate the return using the static method\n",
    "total_return = processdata.get_return_defined_time(data2, start_date, end_date)\n",
    "\n",
    "\n",
    "start_date = processdata.formatDateDt(2021, 1, 1)\n",
    "end_date = processdata.formatDateDt(2024, 1, 1)\n",
    "\n",
    "dStart, dEnd = processdata.get_valid_dates(data2, start_date, end_date)\n",
    "roi = processdata.get_roi_defined_time(data2, dStart, dEnd)\n",
    "mean = processdata.get_mean_between_dates(data2, dStart, dEnd)\n",
    "std = processdata.get_sd_between_dates(data2, dStart, dEnd)\n",
    "cov = processdata.get_cov_between_dates(data2, dStart, dEnd)\n",
    "\n",
    "faang_list = [\"META\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]\n",
    "mult_df = processdata.merge_df_by_column_name('daily_return',  '2020-1-1', '2020-12-31', *faang_list)\n",
    "\n",
    "# Generate a Correlation Matrix\n",
    "mult_df.corr()\n",
    "\n",
    "# # We can look at the correlation between Netflix and the others\n",
    "# mult_df.corr()['NFLX']\n",
    "\n",
    "# # # We can plot this in a bar chart\n",
    "mult_df.corr()['NFLX'].plot(kind='bar')\n",
    "\n",
    "mult_df['NFLX'].var()\n",
    "\n",
    "# Annualize by getting the number of samples and multiply\n",
    "days = len(mult_df.index) # 253\n",
    "\n",
    "nflx_a_var = mult_df['NFLX'].var() * 253\n",
    "nflx_a_var\n",
    "\n",
    "mult_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from yf\n",
    "ticker = 'NFLX'\n",
    "\n",
    "data = api_yf.getFullDataFromYf(ticker)\n",
    "# insert data into sqlLite db\n",
    "db_utils.execute_values(data, 'stock_data', ticker)\n",
    "db_utils.commit()\n",
    "\n",
    "# retrive data from db\n",
    "data = db_utils.get_data_from_db(ticker)\n",
    "print(data.head())\n",
    "\n",
    "# # Plot the closing prices over time using the Date column as x-axis\n",
    "pl.plot_closing_prices(data, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Get the ticker object for NASDAQ Composite Index\n",
    "nasdaq_ticker = yf.Ticker(\"^IXIC\")\n",
    "\n",
    "# Get the list of tickers\n",
    "nasdaq_symbols_list = nasdaq_ticker.tickers['^IXIC'].history().index.get_level_values(1).unique().tolist()\n",
    "\n",
    "# Print the list of tickers\n",
    "print(nasdaq_symbols_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sec_df = df = pd.read_excel('c:\\\\Users\\\\somma\\\\Documents\\\\GIT\\\\pythonForFinance\\\\\\\\database\\\\wilshire_5000_stocks.xlsx')\n",
    "db_utils.insert_wilshire_stocks(sec_df)\n",
    "db_utils.commit()\n",
    "sector = db_utils.get_wilshire_distinct_sectors()\n",
    "tickers = db_utils.get_wilshire_ticker()\n",
    "stockTicker = db_utils.get_ticker_from_stock()\n",
    "print(\"wilshire tickers: \", len(tickers),\"stock tickers : \",len(stockTicker))\n",
    "unique_elements = [x for x in tickers if x not in stockTicker]\n",
    "print(len(tickers)-len(stockTicker),len(unique_elements))\n",
    "stocks_by_sector = db_utils.get_wilshire_ticker_by_sector(\"Industrials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = db_utils.get_wilshire_ticker()\n",
    "\n",
    "print(\"wilshire tickers: \", len(tickers),\"stock tickers : \",len(stockTicker))\n",
    "unique_elements = [x for x in tickers if x not in stockTicker]\n",
    "print(len(tickers)-len(stockTicker),len(unique_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockTicker = db_utils.get_ticker_from_stock()\n",
    "import time\n",
    "\n",
    "start_date = processdata.formatDateDt(2024, 6, 14)\n",
    "end_date = processdata.formatDateDt(2024, 6, 23)\n",
    "\n",
    "for ticker in stockTicker:\n",
    "    df = api_yf.getFullDataFromYf(ticker)\n",
    "    # insert data into db\n",
    "    if df is not None and not df.empty:\n",
    "        db_utils.execute_values(df, 'stock_data', ticker)\n",
    "        db_utils.commit()\n",
    "        time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from yf\n",
    "ticker = 'BNED'\n",
    "start_date = processdata.formatDateDt(2024, 6, 14)\n",
    "end_date = processdata.formatDateDt(2024, 6, 23)\n",
    "\n",
    "data = api_yf.getFullDataFromYf(ticker)\n",
    "# insert data into sqlLite db\n",
    "db_utils.execute_values(data, 'stock_data', ticker)\n",
    "db_utils.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sectors = db_utils.get_wilshire_distinct_sectors()\n",
    "print(sectors)\n",
    "\n",
    "# Create an empty dictionary to store the dataframes\n",
    "sector_dataframes = {}\n",
    "\n",
    "# Loop through each sector and create a dataframe\n",
    "for sector in sectors:\n",
    "    sector_data = db_utils.get_wilshire_df_by_sector(sector)\n",
    "    sector_dataframes[sector] = sector_data\n",
    "\n",
    "def get_rois_for_stocks(stock_df,year):\n",
    "    # Will hold all tickers & stock rois\n",
    "    tickers = []\n",
    "    rois = []\n",
    "\n",
    "    # iterrows provides the index and column for each row in the DF\n",
    "    for index, row in stock_df.iterrows():\n",
    "        df = db_utils.get_data_from_db(row['ticker'])\n",
    "        print('working on', row['ticker'],)\n",
    "        # If we can't find the ticker delete it from the dataframe\n",
    "        if df is None or len(df) < 1:\n",
    "            pass\n",
    "            print(row['ticker'], \" is not available\")\n",
    "        else:          \n",
    "            sdate, edate = processdata.get_valid_dates(df, f'{year}-01-01', f'{year}-12-31')\n",
    "            if sdate != -1:\n",
    "                roi = processdata.get_roi_defined_time(df, sdate, edate)\n",
    "                tickers.append(row['ticker'])\n",
    "                rois.append(roi)\n",
    "    return pd.DataFrame({'ticker':tickers, 'ROI':rois})\n",
    "\n",
    "\n",
    "# health_care = get_rois_for_stocks(health_df)\n",
    "# it = get_rois_for_stocks(it_df)\n",
    "# commun = get_rois_for_stocks(comm_df)\n",
    "# staple = get_rois_for_stocks(staple_df)\n",
    "# discretion = get_rois_for_stocks(discretion_df)\n",
    "# utility = get_rois_for_stocks(utility_df)\n",
    "# finance = get_rois_for_stocks(financial_df)\n",
    "# material = get_rois_for_stocks(material_df)\n",
    "# restate = get_rois_for_stocks(restate_df)\n",
    "# energy = get_rois_for_stocks(energy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_rois_for_stocks(sector_dataframes[sector], year)\n",
    "df[\"sector\"]=sector\n",
    "db_utils.insert_stock_data(year,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2024'\n",
    "df = db_utils.get_data_from_db('BNED')\n",
    "sdate, edate = processdata.get_valid_dates(df, f'{year}-01-01', f'{year}-12-31')\n",
    "if sdate != -1:\n",
    "    roi = processdata.get_roi_defined_time(df, sdate, edate)\n",
    "    print(roi)\n",
    "\n",
    "db_utils.insert_stock_data(year,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010, 2025):\n",
    "    for sector in sectors:\n",
    "        df = get_rois_for_stocks(sector_dataframes[sector], year)\n",
    "        df[\"sector\"]=sector\n",
    "        db_utils.insert_stock_data(year,df)\n",
    "\n",
    "    db_utils.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_utils.get_stock_returns('2016','Technology')\n",
    "df.sort_values(by=['return'], ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010, 2025):\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_utils.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisDf = roisDict['Healthcare']\n",
    "thisDf[\"sector\"]='Healthcare'\n",
    "print(thisDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helatcare =roisDict['Healthcare']\n",
    "helatcare.sort_values(by=['ROI'], ascending=False).head(5)\n",
    "\n",
    "for el in roisDict:\n",
    "    print(\"top 5 \", el)\n",
    "    print(roisDict[el].sort_values(by=['ROI'], ascending=False).head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_list = [\"GNRC\", \"DXCM\", \"AMD\", \"NFLX\", \"COST\", \"TGT\", \"AES\", \"MSCI\", \n",
    "             \"NEM\", \"SBAC\", \"HES\"]\n",
    "\n",
    "mult_df = processdata.merge_df_by_column_name('daily_return',  '2021-01-04', \n",
    "                                  '2024-06-16', *port_list)\n",
    "\n",
    "# Generate a Correlation Matrix\n",
    "mult_df.corr()\n",
    "# Get the number of samples\n",
    "days = len(mult_df.index)\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "date = '2021-01-04'\n",
    "\n",
    "# Fetch initial values using a list comprehension and convert to NumPy array\n",
    "initialValue = np.array([db_utils.get_data_from_db(stock, date, date)['adj_close'].values[0] for stock in port_list])\n",
    "print(\"Initial Values:\", initialValue)\n",
    "\n",
    "# Calculate total investment and mean\n",
    "tot_inv = 4 * np.sum(initialValue)\n",
    "mean = tot_inv / len(initialValue)\n",
    "print(\"Total Investment:\", tot_inv, \"Mean:\", mean)\n",
    "\n",
    "# Calculate stockNum using vectorized operations with NumPy\n",
    "stockNum = np.ceil(mean / initialValue).astype(int)\n",
    "print(\"Weights:\", stockNum)\n",
    "\n",
    "# Calculate the effectiveInvestment using NumPy arrays\n",
    "effectiveInvestment = np.sum(initialValue * stockNum)\n",
    "print(\"Result:\", effectiveInvestment)\n",
    "\n",
    "# Calculate the weights as an array of element-wise initialValue * stockNum / effectiveInvestment\n",
    "weights = (initialValue * stockNum) / effectiveInvestment\n",
    "print(\"Weight Calculations:\", weights)\n",
    "\n",
    "days = len(mult_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "port_var = np.dot(weights.T, np.dot(mult_df.cov() * days, weights))\n",
    "print(\"Portfolio Covariance :\", port_var)\n",
    "print(\"GNRC Var :\", mult_df[\"GNRC\"].var() * days)\n",
    "print(\"NFLX Var :\", mult_df[\"NFLX\"].var() * days)\n",
    "print(mult_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diversifiable Risk = Portfolio Variance - All Weighted Variances\n",
    "def calc_diversifiable_risk(df, tickers, weights):\n",
    "    # Gets number of days\n",
    "    days = len(mult_df.index)\n",
    "    # Calculate covariance of portfolio\n",
    "    port_covar = np.dot(weights.T, np.dot(df.cov() * days, weights)) \n",
    "    \n",
    "    i = 0\n",
    "    while i < len(tickers):\n",
    "        wt_sq = weights[i] ** 2\n",
    "        stk_var = mult_df[tickers[i]].var() * days\n",
    "        wt_var = wt_sq * stk_var\n",
    "        port_covar = port_covar - wt_var\n",
    "        i += 1\n",
    "    return port_covar\n",
    "\n",
    "div_risk = calc_diversifiable_risk(mult_df, port_list, weights)\n",
    "div_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Risk that Can't be Diversified\n",
    "print(\"Systematic Risk :\", (port_var - div_risk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
